{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e335b7c2-1dab-4542-899a-93df8a332085",
   "metadata": {},
   "source": [
    "# Projet Datascientest - Compagnon immo\n",
    "\n",
    "<code>mar25_bds_compagnon_immo_1</code>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2abe2e1b-6205-4e18-994e-770da3ef4d3f",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Modélisation évolution des prix - v5.0\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33daaaff-9ed4-49b1-a614-fa25a43307a6",
   "metadata": {},
   "source": [
    "### Recherche optimisation R2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "aa234ce9-1279-4535-97a0-f1a86d77defc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.preprocessing import RobustScaler, OneHotEncoder, MinMaxScaler, StandardScaler\n",
    "from sklearn.model_selection import TimeSeriesSplit\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.models import Model, Sequential\n",
    "from tensorflow.keras.layers import Input, Dense, Dropout, BatchNormalization, Bidirectional, GRU, LSTM, LayerNormalization\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from tensorflow.keras.layers import Conv1D,  Layer\n",
    "from tensorflow.keras.layers import Activation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87fc1d54-2eaf-492c-b0bb-e44bf0c8ba6e",
   "metadata": {},
   "source": [
    "### Chargement des données nettoyées"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1991678b-0c55-4df7-a455-2a80d4499b72",
   "metadata": {},
   "outputs": [],
   "source": [
    "output_path = '../data/processed/dep_75_cleaned.csv.gz'\n",
    "df_dep75 = pd.read_csv(output_path, low_memory=False, index_col='date_mutation', parse_dates=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18879d7a-89d4-49c2-b84a-429e344daa61",
   "metadata": {},
   "source": [
    "#### Ajout du taux d'inflation annuel, taux livret A et taux moyen bancaire"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "42ebf9cc-a3e6-4104-9933-f86bb3508197",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Source INSEE\n",
    "df_inflation = pd.read_csv('../data/raw/inflation-2020-2024.csv', index_col=0)\n",
    "\n",
    "df_inflation = df_inflation.drop('mois',axis=1)\n",
    "df_inflation.rename(columns={'index': 'mois'}, inplace=True)\n",
    "df_inflation.columns = df_inflation.columns.astype(int)\n",
    "df_inflation[\"mois\"] = df_inflation.index.astype(int)\n",
    "\n",
    "def get_inflation(row):\n",
    "    mois = row['mois']\n",
    "    annee = row['annee']\n",
    "    try:\n",
    "        return df_inflation.loc[mois, annee]\n",
    "    except KeyError:\n",
    "        return np.nan\n",
    "\n",
    "df_dep75['taux_inflation'] = df_dep75.apply(get_inflation, axis=1)\n",
    "\n",
    "# Source Banque de France\n",
    "taux_livret_a = {\n",
    "     2020: 0.50,\n",
    "     2021: 0.50,\n",
    "     2022: 1.38,\n",
    "     2023: 2.50,\n",
    "     2024: 3.00,\n",
    "}\n",
    "taux_moyen_bancaire = {\n",
    "     2020: 0.48,\n",
    "     2021: 0.47,\n",
    "     2022: 0.78,\n",
    "     2023: 1.37,\n",
    "     2024: 1.80,\n",
    "}\n",
    "df_dep75[\"taux_livret_a\"] = df_dep75[\"annee\"].map(taux_livret_a)\n",
    "df_dep75[\"taux_moyen_bancaire\"] = df_dep75[\"annee\"].map(taux_moyen_bancaire)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8300f871-7633-43e0-ba94-e9bcd013b37f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>nature_mutation</th>\n",
       "      <th>valeur_fonciere</th>\n",
       "      <th>code_commune</th>\n",
       "      <th>code_departement</th>\n",
       "      <th>lot1_numero</th>\n",
       "      <th>lot1_surface_carrez</th>\n",
       "      <th>nombre_lots</th>\n",
       "      <th>code_type_local</th>\n",
       "      <th>type_local</th>\n",
       "      <th>surface_reelle_bati</th>\n",
       "      <th>...</th>\n",
       "      <th>code_nature_culture_speciale</th>\n",
       "      <th>surface_terrain</th>\n",
       "      <th>longitude</th>\n",
       "      <th>latitude</th>\n",
       "      <th>prix_m2_vente</th>\n",
       "      <th>annee</th>\n",
       "      <th>mois</th>\n",
       "      <th>taux_inflation</th>\n",
       "      <th>taux_livret_a</th>\n",
       "      <th>taux_moyen_bancaire</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>date_mutation</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2024-04-10</th>\n",
       "      <td>Vente</td>\n",
       "      <td>515000.0</td>\n",
       "      <td>75120</td>\n",
       "      <td>75</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>Appartement</td>\n",
       "      <td>24.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NS</td>\n",
       "      <td>145.0</td>\n",
       "      <td>2.394430</td>\n",
       "      <td>48.874568</td>\n",
       "      <td>21458.333333</td>\n",
       "      <td>2024</td>\n",
       "      <td>4</td>\n",
       "      <td>2.2</td>\n",
       "      <td>3.00</td>\n",
       "      <td>1.80</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-03-25</th>\n",
       "      <td>Vente</td>\n",
       "      <td>14500000.0</td>\n",
       "      <td>75110</td>\n",
       "      <td>75</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>Appartement</td>\n",
       "      <td>44.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NS</td>\n",
       "      <td>771.0</td>\n",
       "      <td>2.365641</td>\n",
       "      <td>48.880592</td>\n",
       "      <td>329545.454545</td>\n",
       "      <td>2022</td>\n",
       "      <td>3</td>\n",
       "      <td>4.5</td>\n",
       "      <td>1.38</td>\n",
       "      <td>0.78</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-11-30</th>\n",
       "      <td>Vente</td>\n",
       "      <td>5310000.0</td>\n",
       "      <td>75111</td>\n",
       "      <td>75</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>Local industriel. commercial ou assimilé</td>\n",
       "      <td>134.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NS</td>\n",
       "      <td>122.0</td>\n",
       "      <td>2.384223</td>\n",
       "      <td>48.851293</td>\n",
       "      <td>39626.865672</td>\n",
       "      <td>2021</td>\n",
       "      <td>11</td>\n",
       "      <td>2.8</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.47</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-04-23</th>\n",
       "      <td>Vente</td>\n",
       "      <td>80150000.0</td>\n",
       "      <td>75106</td>\n",
       "      <td>75</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>Appartement</td>\n",
       "      <td>122.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NS</td>\n",
       "      <td>1532.0</td>\n",
       "      <td>2.325260</td>\n",
       "      <td>48.850175</td>\n",
       "      <td>656967.213115</td>\n",
       "      <td>2024</td>\n",
       "      <td>4</td>\n",
       "      <td>2.2</td>\n",
       "      <td>3.00</td>\n",
       "      <td>1.80</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-03-17</th>\n",
       "      <td>Adjudication</td>\n",
       "      <td>15400000.0</td>\n",
       "      <td>75103</td>\n",
       "      <td>75</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>Local industriel. commercial ou assimilé</td>\n",
       "      <td>421.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NS</td>\n",
       "      <td>349.0</td>\n",
       "      <td>2.359087</td>\n",
       "      <td>48.863926</td>\n",
       "      <td>36579.572447</td>\n",
       "      <td>2020</td>\n",
       "      <td>3</td>\n",
       "      <td>0.7</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.48</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 22 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              nature_mutation  valeur_fonciere  code_commune  \\\n",
       "date_mutation                                                  \n",
       "2024-04-10              Vente         515000.0         75120   \n",
       "2022-03-25              Vente       14500000.0         75110   \n",
       "2021-11-30              Vente        5310000.0         75111   \n",
       "2024-04-23              Vente       80150000.0         75106   \n",
       "2020-03-17       Adjudication       15400000.0         75103   \n",
       "\n",
       "               code_departement  lot1_numero  lot1_surface_carrez  \\\n",
       "date_mutation                                                       \n",
       "2024-04-10                   75            0                  0.0   \n",
       "2022-03-25                   75            0                  0.0   \n",
       "2021-11-30                   75            0                  0.0   \n",
       "2024-04-23                   75            0                  0.0   \n",
       "2020-03-17                   75            0                  0.0   \n",
       "\n",
       "               nombre_lots  code_type_local  \\\n",
       "date_mutation                                 \n",
       "2024-04-10               0              2.0   \n",
       "2022-03-25               0              2.0   \n",
       "2021-11-30               0              4.0   \n",
       "2024-04-23               0              2.0   \n",
       "2020-03-17               0              4.0   \n",
       "\n",
       "                                             type_local  surface_reelle_bati  \\\n",
       "date_mutation                                                                  \n",
       "2024-04-10                                  Appartement                 24.0   \n",
       "2022-03-25                                  Appartement                 44.0   \n",
       "2021-11-30     Local industriel. commercial ou assimilé                134.0   \n",
       "2024-04-23                                  Appartement                122.0   \n",
       "2020-03-17     Local industriel. commercial ou assimilé                421.0   \n",
       "\n",
       "               ...  code_nature_culture_speciale surface_terrain longitude  \\\n",
       "date_mutation  ...                                                           \n",
       "2024-04-10     ...                            NS           145.0  2.394430   \n",
       "2022-03-25     ...                            NS           771.0  2.365641   \n",
       "2021-11-30     ...                            NS           122.0  2.384223   \n",
       "2024-04-23     ...                            NS          1532.0  2.325260   \n",
       "2020-03-17     ...                            NS           349.0  2.359087   \n",
       "\n",
       "                latitude  prix_m2_vente  annee  mois  taux_inflation  \\\n",
       "date_mutation                                                          \n",
       "2024-04-10     48.874568   21458.333333   2024     4             2.2   \n",
       "2022-03-25     48.880592  329545.454545   2022     3             4.5   \n",
       "2021-11-30     48.851293   39626.865672   2021    11             2.8   \n",
       "2024-04-23     48.850175  656967.213115   2024     4             2.2   \n",
       "2020-03-17     48.863926   36579.572447   2020     3             0.7   \n",
       "\n",
       "               taux_livret_a  taux_moyen_bancaire  \n",
       "date_mutation                                      \n",
       "2024-04-10              3.00                 1.80  \n",
       "2022-03-25              1.38                 0.78  \n",
       "2021-11-30              0.50                 0.47  \n",
       "2024-04-23              3.00                 1.80  \n",
       "2020-03-17              0.50                 0.48  \n",
       "\n",
       "[5 rows x 22 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_dep75 = df_dep75[df_dep75['prix_m2_vente'] < 1_000_000]\n",
    "df_dep75 = df_dep75.drop(['numero_disposition', \n",
    "                          'lot2_numero', \n",
    "                          'lot2_surface_carrez',\n",
    "                          'lot3_numero', \n",
    "                          'lot3_surface_carrez',\n",
    "                          'lot4_numero', \n",
    "                          'lot4_surface_carrez', \n",
    "                          'lot5_numero', \n",
    "                          'lot5_surface_carrez'], axis=1)\n",
    "df_dep75.sample(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6245b8ac-01e4-4f20-aee5-fe58c8fd6940",
   "metadata": {},
   "source": [
    "### Deep Learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "818b9298-7c18-4df4-89e4-9f3444992212",
   "metadata": {},
   "outputs": [],
   "source": [
    "def display_scores(y_test_seq, y_pred, model_name, scaler_name):\n",
    "    y_pred = scaler_y.inverse_transform(y_pred)\n",
    "    y_test_seq = scaler_y.inverse_transform(y_test_seq.reshape(-1, 1))\n",
    "    r2 = r2_score(y_test_seq, y_pred)\n",
    "    mae = mean_absolute_error(y_test_seq, y_pred)\n",
    "    rmse = np.sqrt(mean_squared_error(y_test_seq, y_pred))\n",
    "    \n",
    "    scores = pd.DataFrame([{\n",
    "        'Modèle': model_name,\n",
    "        'Scaler': scaler_name,\n",
    "        'MAE': mae,\n",
    "        'RMSE': rmse,\n",
    "        'R2': r2\n",
    "    }])\n",
    "\n",
    "    display(scores)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3548408-4b71-4d16-bb89-22b0458cd109",
   "metadata": {},
   "source": [
    "#### Callbacks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "ddcfb6fb-358a-4d33-8bab-9ce294729c0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau\n",
    "callbacks = [\n",
    "    EarlyStopping(monitor=\"val_loss\", patience=10, restore_best_weights=True),\n",
    "    ReduceLROnPlateau(monitor=\"val_loss\", factor=0.5, patience=5, verbose=1),\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "718110ab-e2b2-4f0c-b4d7-03885295386c",
   "metadata": {},
   "source": [
    "#### Train test Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "bcf7324d-f519-4b6e-b8eb-d6c8de3ddcde",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = df_dep75[df_dep75['annee'] < 2024]\n",
    "df_test = df_dep75[df_dep75['annee'] == 2024]\n",
    "\n",
    "X_train = df_train.drop(['prix_m2_vente'], axis=1)\n",
    "X_test = df_test.drop(['prix_m2_vente'], axis=1)\n",
    "\n",
    "y_train = df_train['prix_m2_vente'].values.reshape(-1, 1)\n",
    "y_test = df_test['prix_m2_vente'].values.reshape(-1, 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad6f1df8-df82-4cbd-8382-e36378f94add",
   "metadata": {},
   "source": [
    "#### Encodage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c178d001-d8b0-49cc-b9c1-ceed52846b8e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Variables catégorielles restantes : 0\n"
     ]
    }
   ],
   "source": [
    "one_hot_cols = ['type_local', 'nature_mutation']\n",
    "ohe = OneHotEncoder(sparse_output=False, handle_unknown='ignore')\n",
    "ohe.fit(X_train[one_hot_cols])\n",
    "\n",
    "X_train_ohe = pd.DataFrame(ohe.transform(X_train[one_hot_cols]), \n",
    "                           columns=ohe.get_feature_names_out(one_hot_cols),\n",
    "                           index=X_train.index)\n",
    "\n",
    "X_test_ohe = pd.DataFrame(ohe.transform(X_test[one_hot_cols]), \n",
    "                          columns=ohe.get_feature_names_out(one_hot_cols),\n",
    "                          index=X_test.index)\n",
    "\n",
    "X_train = X_train.drop(columns=one_hot_cols)\n",
    "X_test = X_test.drop(columns=one_hot_cols)\n",
    "\n",
    "X_train = pd.concat([X_train, X_train_ohe], axis=1)\n",
    "X_test = pd.concat([X_test, X_test_ohe], axis=1)\n",
    "\n",
    "freq_cols = ['code_nature_culture', 'code_nature_culture_speciale', 'code_commune', 'code_departement']\n",
    "\n",
    "for col in freq_cols:\n",
    "    freq_encoding = X_train[col].value_counts(normalize=True)\n",
    "\n",
    "    X_train[col] = X_train[col].map(freq_encoding).fillna(0)\n",
    "    X_test[col] = X_test[col].map(freq_encoding).fillna(0)\n",
    "\n",
    "\n",
    "X_train['lot1_numero'] = (X_train['lot1_numero'] != 0).astype(int)\n",
    "X_test['lot1_numero'] = (X_test['lot1_numero'] != 0).astype(int)\n",
    "\n",
    "print(\"Variables catégorielles restantes :\", len(X_train.select_dtypes('object').columns))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "003f08ec-251e-4d83-bcda-220bfa49265e",
   "metadata": {},
   "outputs": [],
   "source": [
    "robust_x_scaler = RobustScaler()\n",
    "X_train_scaled = robust_x_scaler.fit_transform(X_train)\n",
    "X_test_scaled = robust_x_scaler.transform(X_test)\n",
    "\n",
    "robust_y_scaler = RobustScaler()\n",
    "y_train_scaled = robust_y_scaler.fit_transform(y_train)\n",
    "y_test_scaled = robust_y_scaler.transform(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "16d68a0d-16af-4cde-95ec-5168ff7a962c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "\u001b[1m694/694\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 13ms/step - loss: 0.5084 - val_loss: 0.3452 - learning_rate: 0.0010\n",
      "Epoch 2/50\n",
      "\u001b[1m 12/694\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m6s\u001b[0m 10ms/step - loss: 0.3126"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\tabod\\anaconda3\\Lib\\site-packages\\keras\\src\\callbacks\\early_stopping.py:153: UserWarning: Early stopping conditioned on metric `val_mae` which is not available. Available metrics are: loss,val_loss\n",
      "  current = self.get_monitor_value(logs)\n",
      "C:\\Users\\tabod\\anaconda3\\Lib\\site-packages\\keras\\src\\callbacks\\callback_list.py:145: UserWarning: Learning rate reduction is conditioned on metric `val_mae` which is not available. Available metrics are: loss,val_loss,learning_rate.\n",
      "  callback.on_epoch_end(epoch, logs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m694/694\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 11ms/step - loss: 0.2932 - val_loss: 0.3493 - learning_rate: 0.0010\n",
      "Epoch 3/50\n",
      "\u001b[1m694/694\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 11ms/step - loss: 0.2647 - val_loss: 0.3290 - learning_rate: 0.0010\n",
      "Epoch 4/50\n",
      "\u001b[1m694/694\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 11ms/step - loss: 0.2532 - val_loss: 0.2807 - learning_rate: 0.0010\n",
      "Epoch 5/50\n",
      "\u001b[1m694/694\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 11ms/step - loss: 0.2512 - val_loss: 0.2803 - learning_rate: 0.0010\n",
      "Epoch 6/50\n",
      "\u001b[1m694/694\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 13ms/step - loss: 0.2414 - val_loss: 0.2906 - learning_rate: 0.0010\n",
      "Epoch 7/50\n",
      "\u001b[1m694/694\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 11ms/step - loss: 0.2433 - val_loss: 0.2881 - learning_rate: 0.0010\n",
      "Epoch 8/50\n",
      "\u001b[1m694/694\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 11ms/step - loss: 0.2395 - val_loss: 0.2791 - learning_rate: 0.0010\n",
      "Epoch 9/50\n",
      "\u001b[1m694/694\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 11ms/step - loss: 0.2437 - val_loss: 0.2768 - learning_rate: 0.0010\n",
      "Epoch 10/50\n",
      "\u001b[1m694/694\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 11ms/step - loss: 0.2399 - val_loss: 0.2665 - learning_rate: 0.0010\n",
      "Epoch 11/50\n",
      "\u001b[1m694/694\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 11ms/step - loss: 0.2446 - val_loss: 0.2641 - learning_rate: 0.0010\n",
      "Epoch 12/50\n",
      "\u001b[1m694/694\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 11ms/step - loss: 0.2256 - val_loss: 0.2780 - learning_rate: 0.0010\n",
      "Epoch 13/50\n",
      "\u001b[1m694/694\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 11ms/step - loss: 0.2392 - val_loss: 0.2649 - learning_rate: 0.0010\n",
      "Epoch 14/50\n",
      "\u001b[1m694/694\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 11ms/step - loss: 0.2486 - val_loss: 0.2630 - learning_rate: 0.0010\n",
      "Epoch 15/50\n",
      "\u001b[1m694/694\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 11ms/step - loss: 0.2423 - val_loss: 0.2807 - learning_rate: 0.0010\n",
      "Epoch 16/50\n",
      "\u001b[1m694/694\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 11ms/step - loss: 0.2336 - val_loss: 0.2601 - learning_rate: 0.0010\n",
      "Epoch 17/50\n",
      "\u001b[1m694/694\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 11ms/step - loss: 0.2347 - val_loss: 0.2912 - learning_rate: 0.0010\n",
      "Epoch 18/50\n",
      "\u001b[1m694/694\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 11ms/step - loss: 0.2277 - val_loss: 0.2672 - learning_rate: 0.0010\n",
      "Epoch 19/50\n",
      "\u001b[1m694/694\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 11ms/step - loss: 0.2246 - val_loss: 0.2667 - learning_rate: 0.0010\n",
      "Epoch 20/50\n",
      "\u001b[1m694/694\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 11ms/step - loss: 0.2383 - val_loss: 0.2952 - learning_rate: 0.0010\n",
      "Epoch 21/50\n",
      "\u001b[1m694/694\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 11ms/step - loss: 0.2198 - val_loss: 0.2902 - learning_rate: 0.0010\n",
      "Epoch 22/50\n",
      "\u001b[1m694/694\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 11ms/step - loss: 0.2321 - val_loss: 0.2789 - learning_rate: 0.0010\n",
      "Epoch 23/50\n",
      "\u001b[1m694/694\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 11ms/step - loss: 0.2297 - val_loss: 0.2863 - learning_rate: 0.0010\n",
      "Epoch 24/50\n",
      "\u001b[1m694/694\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 11ms/step - loss: 0.2297 - val_loss: 0.2710 - learning_rate: 0.0010\n",
      "Epoch 25/50\n",
      "\u001b[1m694/694\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 11ms/step - loss: 0.2198 - val_loss: 0.2632 - learning_rate: 0.0010\n",
      "Epoch 26/50\n",
      "\u001b[1m694/694\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 11ms/step - loss: 0.2291 - val_loss: 0.2680 - learning_rate: 0.0010\n",
      "Epoch 27/50\n",
      "\u001b[1m694/694\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 11ms/step - loss: 0.2175 - val_loss: 0.2691 - learning_rate: 0.0010\n",
      "Epoch 28/50\n",
      "\u001b[1m694/694\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 11ms/step - loss: 0.2231 - val_loss: 0.2976 - learning_rate: 0.0010\n",
      "Epoch 29/50\n",
      "\u001b[1m694/694\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 12ms/step - loss: 0.2156 - val_loss: 0.2796 - learning_rate: 0.0010\n",
      "Epoch 30/50\n",
      "\u001b[1m694/694\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 12ms/step - loss: 0.2218 - val_loss: 0.2846 - learning_rate: 0.0010\n",
      "Epoch 31/50\n",
      "\u001b[1m694/694\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 12ms/step - loss: 0.2172 - val_loss: 0.2924 - learning_rate: 0.0010\n",
      "Epoch 32/50\n",
      "\u001b[1m694/694\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 12ms/step - loss: 0.2121 - val_loss: 0.2699 - learning_rate: 0.0010\n",
      "Epoch 33/50\n",
      "\u001b[1m694/694\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 11ms/step - loss: 0.2220 - val_loss: 0.2836 - learning_rate: 0.0010\n",
      "Epoch 34/50\n",
      "\u001b[1m694/694\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 11ms/step - loss: 0.2151 - val_loss: 0.2930 - learning_rate: 0.0010\n",
      "Epoch 35/50\n",
      "\u001b[1m694/694\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 11ms/step - loss: 0.2155 - val_loss: 0.2862 - learning_rate: 0.0010\n",
      "Epoch 36/50\n",
      "\u001b[1m694/694\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 12ms/step - loss: 0.2171 - val_loss: 0.2820 - learning_rate: 0.0010\n",
      "Epoch 37/50\n",
      "\u001b[1m694/694\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 12ms/step - loss: 0.2133 - val_loss: 0.2899 - learning_rate: 0.0010\n",
      "Epoch 38/50\n",
      "\u001b[1m694/694\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 12ms/step - loss: 0.2072 - val_loss: 0.2783 - learning_rate: 0.0010\n",
      "Epoch 39/50\n",
      "\u001b[1m694/694\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 11ms/step - loss: 0.2092 - val_loss: 0.2879 - learning_rate: 0.0010\n",
      "Epoch 40/50\n",
      "\u001b[1m694/694\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 11ms/step - loss: 0.2098 - val_loss: 0.2908 - learning_rate: 0.0010\n",
      "Epoch 41/50\n",
      "\u001b[1m694/694\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 11ms/step - loss: 0.2090 - val_loss: 0.3187 - learning_rate: 0.0010\n",
      "Epoch 42/50\n",
      "\u001b[1m694/694\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 11ms/step - loss: 0.2105 - val_loss: 0.2924 - learning_rate: 0.0010\n",
      "Epoch 43/50\n",
      "\u001b[1m694/694\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 11ms/step - loss: 0.2063 - val_loss: 0.3122 - learning_rate: 0.0010\n",
      "Epoch 44/50\n",
      "\u001b[1m694/694\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 11ms/step - loss: 0.2112 - val_loss: 0.2766 - learning_rate: 0.0010\n",
      "Epoch 45/50\n",
      "\u001b[1m694/694\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 11ms/step - loss: 0.2066 - val_loss: 0.2972 - learning_rate: 0.0010\n",
      "Epoch 46/50\n",
      "\u001b[1m694/694\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 11ms/step - loss: 0.2072 - val_loss: 0.2923 - learning_rate: 0.0010\n",
      "Epoch 47/50\n",
      "\u001b[1m694/694\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 11ms/step - loss: 0.2057 - val_loss: 0.2884 - learning_rate: 0.0010\n",
      "Epoch 48/50\n",
      "\u001b[1m694/694\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 11ms/step - loss: 0.2021 - val_loss: 0.3071 - learning_rate: 0.0010\n",
      "Epoch 49/50\n",
      "\u001b[1m694/694\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 11ms/step - loss: 0.2044 - val_loss: 0.2960 - learning_rate: 0.0010\n",
      "Epoch 50/50\n",
      "\u001b[1m694/694\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 11ms/step - loss: 0.2037 - val_loss: 0.2949 - learning_rate: 0.0010\n",
      "\u001b[1m98/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 11ms/step\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'display_scores' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[41], line 39\u001b[0m\n\u001b[0;32m     36\u001b[0m history_hybrid \u001b[38;5;241m=\u001b[39m model_bi_gru_lstm\u001b[38;5;241m.\u001b[39mfit(X_train_seq, y_train_seq, epochs\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m50\u001b[39m, batch_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m16\u001b[39m, validation_data\u001b[38;5;241m=\u001b[39m(X_test_seq, y_test_seq), callbacks\u001b[38;5;241m=\u001b[39m[callbacks])\n\u001b[0;32m     38\u001b[0m y_pred_bi_gru_lstm \u001b[38;5;241m=\u001b[39m model_bi_gru_lstm\u001b[38;5;241m.\u001b[39mpredict(X_test_seq)\n\u001b[1;32m---> 39\u001b[0m display_scores(y_test_seq, y_pred_bi_gru_lstm, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mBidirectional GRU + LSTM\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mrobust\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'display_scores' is not defined"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.losses import Huber\n",
    "\n",
    "timesteps = 12  \n",
    "input_dim = X_train_scaled.shape[1]\n",
    "\n",
    "inputs = Input(shape=(timesteps, input_dim))\n",
    "\n",
    "x = Conv1D(filters=128, kernel_size=5, activation=\"relu\")(inputs)\n",
    "x = Dropout(0.35)(x)\n",
    "x = LayerNormalization()(x)\n",
    "\n",
    "x = Bidirectional(GRU(128, activation=\"tanh\", return_sequences=True))(x)\n",
    "x = Dropout(0.3)(x)\n",
    "x = LayerNormalization()(x)\n",
    "\n",
    "x = Bidirectional(LSTM(64, activation=\"tanh\", return_sequences=True))(x)\n",
    "x = Dropout(0.3)(x)\n",
    "x = LayerNormalization()(x)\n",
    "\n",
    "x = GRU(32, activation=\"tanh\", return_sequences=False)(x)\n",
    "x = Dropout(0.2)(x)\n",
    "\n",
    "x = Dense(64, activation=\"swish\")(x)\n",
    "x = BatchNormalization()(x)\n",
    "x = Dropout(0.2)(x)\n",
    "\n",
    "outputs = Dense(1)(x)\n",
    "\n",
    "model_bi_gru_lstm = Model(inputs=inputs, outputs=outputs)\n",
    "\n",
    "model_bi_gru_lstm.compile(optimizer=\"RMSprop\", loss=Huber())\n",
    "\n",
    "X_train_seq, y_train_seq = create_sequences(X_train_scaled, y_train_scaled, timesteps)\n",
    "X_test_seq, y_test_seq = create_sequences(X_test_scaled, y_test_scaled, timesteps)\n",
    "\n",
    "history_hybrid = model_bi_gru_lstm.fit(X_train_seq, y_train_seq, epochs=50, batch_size=16, validation_data=(X_test_seq, y_test_seq), callbacks=[callbacks])\n",
    "\n",
    "y_pred_bi_gru_lstm = model_bi_gru_lstm.predict(X_test_seq)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "a9b7e53b-7be3-47d1-bc97-39b1174eb4f4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Modèle</th>\n",
       "      <th>Scaler</th>\n",
       "      <th>MAE</th>\n",
       "      <th>RMSE</th>\n",
       "      <th>R2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Bidirectional GRU + LSTM</td>\n",
       "      <td>robust</td>\n",
       "      <td>124336.189735</td>\n",
       "      <td>185566.537182</td>\n",
       "      <td>0.28966</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     Modèle  Scaler            MAE           RMSE       R2\n",
       "0  Bidirectional GRU + LSTM  robust  124336.189735  185566.537182  0.28966"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "scaler_y = robust_y_scaler\n",
    "display_scores(y_test_seq, y_pred_bi_gru_lstm, 'Bidirectional GRU + LSTM', 'robust')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "81e83194-1ee4-4926-9836-a54b303712b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fit_and_evaluate(model, train_set, test_set, learning_rate, epochs=50):\n",
    "    opt = tf.keras.optimizers.SGD(learning_rate=learning_rate, momentum=0.9)\n",
    "    model.compile(loss=tf.keras.losses.Huber(), optimizer=opt, metrics=[\"mae\"])\n",
    "    history = model.fit(train_set, validation_data=test_set, epochs=epochs,\n",
    "                        callbacks=[callbacks])\n",
    "    valid_loss, valid_mae = model.evaluate(test_set)\n",
    "    return valid_mae * 1e6\n",
    "\n",
    "def create_sequences(X, y, timesteps):\n",
    "    X_seq, y_seq = [], []\n",
    "    for i in range(len(X) - timesteps):\n",
    "        X_seq.append(X[i:i+timesteps])\n",
    "        y_seq.append(y[i+timesteps])\n",
    "    return np.array(X_seq), np.array(y_seq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "94eccb8a-b8cd-40a1-b6ec-cec23b95af7b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\tabod\\anaconda3\\Lib\\site-packages\\keras\\src\\layers\\rnn\\rnn.py:200: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    }
   ],
   "source": [
    "X_train_seq, y_train_seq = create_sequences(X_train_scaled, y_train_scaled, timesteps=12)\n",
    "X_test_seq, y_test_seq = create_sequences(X_test_scaled, y_test_scaled, timesteps=12)\n",
    "\n",
    "tf.random.set_seed(42)\n",
    "model = tf.keras.Sequential([\n",
    "    tf.keras.layers.SimpleRNN(1, input_shape=[12, X_train_seq.shape[2]])\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "2d71d522-78f6-4925-9e83-e86f33afb4af",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "\u001b[1m694/694\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 0.3268 - mae: 0.6440 - val_loss: 0.3173 - val_mae: 0.6413 - learning_rate: 0.0200\n",
      "Epoch 2/50\n",
      "\u001b[1m694/694\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.2990 - mae: 0.6032 - val_loss: 0.3139 - val_mae: 0.6377 - learning_rate: 0.0200\n",
      "Epoch 3/50\n",
      "\u001b[1m694/694\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.2947 - mae: 0.5988 - val_loss: 0.3178 - val_mae: 0.6367 - learning_rate: 0.0200\n",
      "Epoch 4/50\n",
      "\u001b[1m694/694\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.3057 - mae: 0.6123 - val_loss: 0.3100 - val_mae: 0.6261 - learning_rate: 0.0200\n",
      "Epoch 5/50\n",
      "\u001b[1m694/694\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.2945 - mae: 0.5923 - val_loss: 0.3147 - val_mae: 0.6335 - learning_rate: 0.0200\n",
      "Epoch 6/50\n",
      "\u001b[1m694/694\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.2947 - mae: 0.5949 - val_loss: 0.3088 - val_mae: 0.6253 - learning_rate: 0.0200\n",
      "Epoch 7/50\n",
      "\u001b[1m694/694\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.2936 - mae: 0.5956 - val_loss: 0.3183 - val_mae: 0.6316 - learning_rate: 0.0200\n",
      "Epoch 8/50\n",
      "\u001b[1m694/694\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.2952 - mae: 0.5973 - val_loss: 0.3149 - val_mae: 0.6278 - learning_rate: 0.0200\n",
      "Epoch 9/50\n",
      "\u001b[1m694/694\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.2949 - mae: 0.5973 - val_loss: 0.3097 - val_mae: 0.6239 - learning_rate: 0.0200\n",
      "Epoch 10/50\n",
      "\u001b[1m694/694\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.2947 - mae: 0.5977 - val_loss: 0.3102 - val_mae: 0.6155 - learning_rate: 0.0200\n",
      "Epoch 11/50\n",
      "\u001b[1m694/694\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.2948 - mae: 0.5956 - val_loss: 0.3245 - val_mae: 0.6357 - learning_rate: 0.0200\n",
      "Epoch 12/50\n",
      "\u001b[1m694/694\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.2988 - mae: 0.6005 - val_loss: 0.3288 - val_mae: 0.6454 - learning_rate: 0.0200\n",
      "Epoch 13/50\n",
      "\u001b[1m694/694\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.2970 - mae: 0.5981 - val_loss: 0.3239 - val_mae: 0.6371 - learning_rate: 0.0200\n",
      "Epoch 14/50\n",
      "\u001b[1m694/694\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.3010 - mae: 0.6063 - val_loss: 0.3168 - val_mae: 0.6366 - learning_rate: 0.0200\n",
      "Epoch 15/50\n",
      "\u001b[1m658/694\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.2989 - mae: 0.6025\n",
      "Epoch 15: ReduceLROnPlateau reducing learning rate to 0.009999999776482582.\n",
      "\u001b[1m694/694\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.2974 - mae: 0.6007 - val_loss: 0.3223 - val_mae: 0.6362 - learning_rate: 0.0200\n",
      "Epoch 16/50\n",
      "\u001b[1m694/694\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.2955 - mae: 0.5948 - val_loss: 0.3060 - val_mae: 0.6113 - learning_rate: 0.0100\n",
      "Epoch 17/50\n",
      "\u001b[1m694/694\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.2854 - mae: 0.5805 - val_loss: 0.3004 - val_mae: 0.6022 - learning_rate: 0.0100\n",
      "Epoch 18/50\n",
      "\u001b[1m694/694\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.2903 - mae: 0.5855 - val_loss: 0.3010 - val_mae: 0.6084 - learning_rate: 0.0100\n",
      "Epoch 19/50\n",
      "\u001b[1m694/694\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.2883 - mae: 0.5831 - val_loss: 0.2997 - val_mae: 0.6049 - learning_rate: 0.0100\n",
      "Epoch 20/50\n",
      "\u001b[1m694/694\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.2860 - mae: 0.5813 - val_loss: 0.3011 - val_mae: 0.6075 - learning_rate: 0.0100\n",
      "Epoch 21/50\n",
      "\u001b[1m694/694\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.2918 - mae: 0.5928 - val_loss: 0.3040 - val_mae: 0.6089 - learning_rate: 0.0100\n",
      "Epoch 22/50\n",
      "\u001b[1m684/694\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.2870 - mae: 0.5820\n",
      "Epoch 22: ReduceLROnPlateau reducing learning rate to 0.004999999888241291.\n",
      "\u001b[1m694/694\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.2866 - mae: 0.5815 - val_loss: 0.3000 - val_mae: 0.6076 - learning_rate: 0.0100\n",
      "Epoch 23/50\n",
      "\u001b[1m694/694\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.2848 - mae: 0.5766 - val_loss: 0.2991 - val_mae: 0.6013 - learning_rate: 0.0050\n",
      "Epoch 24/50\n",
      "\u001b[1m694/694\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.2803 - mae: 0.5697 - val_loss: 0.2956 - val_mae: 0.6014 - learning_rate: 0.0050\n",
      "Epoch 25/50\n",
      "\u001b[1m694/694\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.2793 - mae: 0.5689 - val_loss: 0.2996 - val_mae: 0.5994 - learning_rate: 0.0050\n",
      "Epoch 26/50\n",
      "\u001b[1m694/694\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.2796 - mae: 0.5690 - val_loss: 0.2998 - val_mae: 0.6000 - learning_rate: 0.0050\n",
      "Epoch 27/50\n",
      "\u001b[1m694/694\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.2797 - mae: 0.5688 - val_loss: 0.2983 - val_mae: 0.6015 - learning_rate: 0.0050\n",
      "Epoch 28/50\n",
      "\u001b[1m694/694\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.2802 - mae: 0.5699 - val_loss: 0.2960 - val_mae: 0.6015 - learning_rate: 0.0050\n",
      "Epoch 29/50\n",
      "\u001b[1m694/694\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.2830 - mae: 0.5758 - val_loss: 0.2985 - val_mae: 0.6040 - learning_rate: 0.0050\n",
      "Epoch 30/50\n",
      "\u001b[1m673/694\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.2809 - mae: 0.5704\n",
      "Epoch 30: ReduceLROnPlateau reducing learning rate to 0.0024999999441206455.\n",
      "\u001b[1m694/694\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.2801 - mae: 0.5695 - val_loss: 0.3004 - val_mae: 0.6019 - learning_rate: 0.0050\n",
      "Epoch 31/50\n",
      "\u001b[1m694/694\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.2792 - mae: 0.5664 - val_loss: 0.2967 - val_mae: 0.5915 - learning_rate: 0.0025\n",
      "Epoch 32/50\n",
      "\u001b[1m694/694\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.2774 - mae: 0.5661 - val_loss: 0.2946 - val_mae: 0.5897 - learning_rate: 0.0025\n",
      "Epoch 33/50\n",
      "\u001b[1m694/694\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.2768 - mae: 0.5639 - val_loss: 0.2948 - val_mae: 0.5899 - learning_rate: 0.0025\n",
      "Epoch 34/50\n",
      "\u001b[1m694/694\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.2754 - mae: 0.5619 - val_loss: 0.2957 - val_mae: 0.5913 - learning_rate: 0.0025\n",
      "Epoch 35/50\n",
      "\u001b[1m694/694\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.2762 - mae: 0.5634 - val_loss: 0.2953 - val_mae: 0.5922 - learning_rate: 0.0025\n",
      "Epoch 36/50\n",
      "\u001b[1m694/694\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.2764 - mae: 0.5638 - val_loss: 0.2947 - val_mae: 0.5910 - learning_rate: 0.0025\n",
      "Epoch 37/50\n",
      "\u001b[1m664/694\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.2808 - mae: 0.5703\n",
      "Epoch 37: ReduceLROnPlateau reducing learning rate to 0.0012499999720603228.\n",
      "\u001b[1m694/694\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.2797 - mae: 0.5688 - val_loss: 0.2955 - val_mae: 0.5915 - learning_rate: 0.0025\n",
      "Epoch 38/50\n",
      "\u001b[1m694/694\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.2764 - mae: 0.5634 - val_loss: 0.2935 - val_mae: 0.5861 - learning_rate: 0.0012\n",
      "Epoch 39/50\n",
      "\u001b[1m694/694\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.2762 - mae: 0.5628 - val_loss: 0.2935 - val_mae: 0.5863 - learning_rate: 0.0012\n",
      "Epoch 40/50\n",
      "\u001b[1m694/694\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.2765 - mae: 0.5629 - val_loss: 0.2935 - val_mae: 0.5861 - learning_rate: 0.0012\n",
      "Epoch 41/50\n",
      "\u001b[1m694/694\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.2764 - mae: 0.5627 - val_loss: 0.2934 - val_mae: 0.5859 - learning_rate: 0.0012\n",
      "Epoch 42/50\n",
      "\u001b[1m694/694\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.2762 - mae: 0.5624 - val_loss: 0.2935 - val_mae: 0.5860 - learning_rate: 0.0012\n",
      "Epoch 43/50\n",
      "\u001b[1m694/694\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.2763 - mae: 0.5627 - val_loss: 0.2935 - val_mae: 0.5861 - learning_rate: 0.0012\n",
      "Epoch 44/50\n",
      "\u001b[1m694/694\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.2763 - mae: 0.5626 - val_loss: 0.2935 - val_mae: 0.5862 - learning_rate: 0.0012\n",
      "Epoch 45/50\n",
      "\u001b[1m694/694\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.2761 - mae: 0.5624 - val_loss: 0.2935 - val_mae: 0.5863 - learning_rate: 0.0012\n",
      "Epoch 46/50\n",
      "\u001b[1m676/694\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.2766 - mae: 0.5626\n",
      "Epoch 46: ReduceLROnPlateau reducing learning rate to 0.0006249999860301614.\n",
      "\u001b[1m694/694\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.2759 - mae: 0.5617 - val_loss: 0.2935 - val_mae: 0.5864 - learning_rate: 0.0012\n",
      "Epoch 47/50\n",
      "\u001b[1m694/694\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.2754 - mae: 0.5606 - val_loss: 0.2981 - val_mae: 0.5874 - learning_rate: 6.2500e-04\n",
      "Epoch 48/50\n",
      "\u001b[1m694/694\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.2762 - mae: 0.5622 - val_loss: 0.2958 - val_mae: 0.5831 - learning_rate: 6.2500e-04\n",
      "Epoch 49/50\n",
      "\u001b[1m694/694\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.2754 - mae: 0.5621 - val_loss: 0.2960 - val_mae: 0.5832 - learning_rate: 6.2500e-04\n",
      "Epoch 50/50\n",
      "\u001b[1m694/694\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.2754 - mae: 0.5620 - val_loss: 0.2961 - val_mae: 0.5832 - learning_rate: 6.2500e-04\n",
      "\u001b[1m195/195\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 952us/step - loss: 0.2855 - mae: 0.5715\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "583127.9754638672"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_set = tf.data.Dataset.from_tensor_slices((X_train_seq, y_train_seq)).batch(16)\n",
    "test_set = tf.data.Dataset.from_tensor_slices((X_test_seq, y_test_seq)).batch(16)\n",
    "\n",
    "fit_and_evaluate(model, train_set, test_set, learning_rate=0.02)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "bf29c61b-70a1-42bd-8b0e-3d06fa2123e7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m195/195\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Modèle</th>\n",
       "      <th>Scaler</th>\n",
       "      <th>MAE</th>\n",
       "      <th>RMSE</th>\n",
       "      <th>R2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>RNN</td>\n",
       "      <td>robust</td>\n",
       "      <td>0.583128</td>\n",
       "      <td>0.872974</td>\n",
       "      <td>0.270143</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Modèle  Scaler       MAE      RMSE        R2\n",
       "0    RNN  robust  0.583128  0.872974  0.270143"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred = model.predict(test_set.map(lambda x, y: x))\n",
    "y_true = test_set.map(lambda x, y: y).unbatch()\n",
    "y_true = np.array([y.numpy() for y in y_true])\n",
    "\n",
    "r2 = r2_score(y_true, y_pred)\n",
    "mae = mean_absolute_error(y_true, y_pred)\n",
    "rmse = np.sqrt(mean_squared_error(y_true, y_pred))\n",
    "results_df = pd.DataFrame([{\n",
    "    'Modèle': 'RNN',\n",
    "    'Scaler': 'robust',\n",
    "    'MAE': mae,\n",
    "    'RMSE': rmse,\n",
    "    'R2': r2\n",
    "}])\n",
    "results_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "7bcc5c05-06ee-4703-8bab-e66bc136e9e0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\tabod\\anaconda3\\Lib\\site-packages\\keras\\src\\layers\\rnn\\rnn.py:200: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m694/694\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 4ms/step - loss: 0.3623 - mae: 0.6890 - val_loss: 0.3213 - val_mae: 0.6227 - learning_rate: 0.0100\n",
      "Epoch 2/50\n",
      "\u001b[1m694/694\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 0.2730 - mae: 0.5658 - val_loss: 0.3089 - val_mae: 0.6068 - learning_rate: 0.0100\n",
      "Epoch 3/50\n",
      "\u001b[1m694/694\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 0.2588 - mae: 0.5422 - val_loss: 0.3008 - val_mae: 0.5984 - learning_rate: 0.0100\n",
      "Epoch 4/50\n",
      "\u001b[1m694/694\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 0.2532 - mae: 0.5323 - val_loss: 0.3000 - val_mae: 0.5973 - learning_rate: 0.0100\n",
      "Epoch 5/50\n",
      "\u001b[1m694/694\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 0.2499 - mae: 0.5282 - val_loss: 0.2997 - val_mae: 0.5967 - learning_rate: 0.0100\n",
      "Epoch 6/50\n",
      "\u001b[1m694/694\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 0.2471 - mae: 0.5242 - val_loss: 0.2989 - val_mae: 0.5967 - learning_rate: 0.0100\n",
      "Epoch 7/50\n",
      "\u001b[1m694/694\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 0.2440 - mae: 0.5195 - val_loss: 0.2967 - val_mae: 0.5960 - learning_rate: 0.0100\n",
      "Epoch 8/50\n",
      "\u001b[1m694/694\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 0.2412 - mae: 0.5153 - val_loss: 0.2966 - val_mae: 0.5985 - learning_rate: 0.0100\n",
      "Epoch 9/50\n",
      "\u001b[1m694/694\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 0.2387 - mae: 0.5122 - val_loss: 0.2976 - val_mae: 0.6032 - learning_rate: 0.0100\n",
      "Epoch 10/50\n",
      "\u001b[1m694/694\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 0.2363 - mae: 0.5096 - val_loss: 0.2976 - val_mae: 0.6095 - learning_rate: 0.0100\n",
      "Epoch 11/50\n",
      "\u001b[1m694/694\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 0.2334 - mae: 0.5063 - val_loss: 0.3019 - val_mae: 0.6235 - learning_rate: 0.0100\n",
      "Epoch 12/50\n",
      "\u001b[1m688/694\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.2295 - mae: 0.5011\n",
      "Epoch 12: ReduceLROnPlateau reducing learning rate to 0.004999999888241291.\n",
      "\u001b[1m694/694\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 0.2294 - mae: 0.5009 - val_loss: 0.3079 - val_mae: 0.6341 - learning_rate: 0.0100\n",
      "Epoch 13/50\n",
      "\u001b[1m694/694\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 0.2206 - mae: 0.4875 - val_loss: 0.2961 - val_mae: 0.6064 - learning_rate: 0.0050\n",
      "Epoch 14/50\n",
      "\u001b[1m694/694\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 0.2137 - mae: 0.4781 - val_loss: 0.2992 - val_mae: 0.6101 - learning_rate: 0.0050\n",
      "Epoch 15/50\n",
      "\u001b[1m694/694\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 0.2090 - mae: 0.4728 - val_loss: 0.3026 - val_mae: 0.6143 - learning_rate: 0.0050\n",
      "Epoch 16/50\n",
      "\u001b[1m694/694\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 0.2053 - mae: 0.4684 - val_loss: 0.3078 - val_mae: 0.6199 - learning_rate: 0.0050\n",
      "Epoch 17/50\n",
      "\u001b[1m693/694\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.2016 - mae: 0.4639\n",
      "Epoch 17: ReduceLROnPlateau reducing learning rate to 0.0024999999441206455.\n",
      "\u001b[1m694/694\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 0.2016 - mae: 0.4638 - val_loss: 0.3140 - val_mae: 0.6261 - learning_rate: 0.0050\n",
      "\u001b[1m195/195\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.2916 - mae: 0.5879\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "595975.6374359131"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.random.set_seed(42)\n",
    "deep_model = tf.keras.Sequential([\n",
    "    tf.keras.layers.SimpleRNN(32, return_sequences=True, input_shape=[12, X_train_seq.shape[2]]),\n",
    "    tf.keras.layers.SimpleRNN(32, return_sequences=True),\n",
    "    tf.keras.layers.SimpleRNN(32),\n",
    "    tf.keras.layers.Dense(1)\n",
    "])\n",
    "fit_and_evaluate(deep_model, train_set, test_set, learning_rate=0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "e05edce0-4ae6-4950-9dad-88cdd06bc462",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m195/195\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Modèle</th>\n",
       "      <th>Scaler</th>\n",
       "      <th>MAE</th>\n",
       "      <th>RMSE</th>\n",
       "      <th>R2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>RNN</td>\n",
       "      <td>robust</td>\n",
       "      <td>0.595976</td>\n",
       "      <td>0.880505</td>\n",
       "      <td>0.257495</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Modèle  Scaler       MAE      RMSE        R2\n",
       "0    RNN  robust  0.595976  0.880505  0.257495"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred_dm = deep_model.predict(test_set.map(lambda x, y: x))\n",
    "y_true_dm = test_set.map(lambda x, y: y).unbatch()\n",
    "y_true_dm = np.array([y.numpy() for y in y_true_dm])\n",
    "\n",
    "r2 = r2_score(y_true_dm, y_pred_dm)\n",
    "mae = mean_absolute_error(y_true_dm, y_pred_dm)\n",
    "rmse = np.sqrt(mean_squared_error(y_true_dm, y_pred_dm))\n",
    "results_df = pd.DataFrame([{\n",
    "    'Modèle': 'RNN',\n",
    "    'Scaler': 'robust',\n",
    "    'MAE': mae,\n",
    "    'RMSE': rmse,\n",
    "    'R2': r2\n",
    "}])\n",
    "results_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c646a750-fc52-4827-96e6-41575f7cd941",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "id": "4b2ace58-fc94-4530-b6d9-ecaf84f91ba5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "\u001b[1m347/347\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 18ms/step - loss: 0.6835 - mae: 0.5825 - val_loss: 0.6695 - val_mae: 0.5760 - learning_rate: 0.0010\n",
      "Epoch 2/10\n",
      "\u001b[1m347/347\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 17ms/step - loss: 0.6177 - mae: 0.5390 - val_loss: 0.7118 - val_mae: 0.5983 - learning_rate: 0.0010\n",
      "Epoch 3/10\n",
      "\u001b[1m347/347\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 16ms/step - loss: 0.5835 - mae: 0.5177 - val_loss: 0.6557 - val_mae: 0.5869 - learning_rate: 0.0010\n",
      "Epoch 4/10\n",
      "\u001b[1m347/347\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 17ms/step - loss: 0.6000 - mae: 0.5222 - val_loss: 0.7320 - val_mae: 0.5649 - learning_rate: 0.0010\n",
      "Epoch 5/10\n",
      "\u001b[1m347/347\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 17ms/step - loss: 0.5683 - mae: 0.5039 - val_loss: 0.7246 - val_mae: 0.5572 - learning_rate: 0.0010\n",
      "Epoch 6/10\n",
      "\u001b[1m347/347\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 16ms/step - loss: 0.5767 - mae: 0.5085 - val_loss: 0.7322 - val_mae: 0.5536 - learning_rate: 0.0010\n",
      "Epoch 7/10\n",
      "\u001b[1m347/347\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 16ms/step - loss: 0.5789 - mae: 0.5104 - val_loss: 0.6887 - val_mae: 0.5782 - learning_rate: 0.0010\n",
      "Epoch 8/10\n",
      "\u001b[1m346/347\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 0.5652 - mae: 0.5041\n",
      "Epoch 8: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "\u001b[1m347/347\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 17ms/step - loss: 0.5652 - mae: 0.5041 - val_loss: 0.7137 - val_mae: 0.5594 - learning_rate: 0.0010\n",
      "Epoch 9/10\n",
      "\u001b[1m347/347\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 16ms/step - loss: 0.5249 - mae: 0.4780 - val_loss: 0.6734 - val_mae: 0.5581 - learning_rate: 5.0000e-04\n",
      "Epoch 10/10\n",
      "\u001b[1m347/347\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 16ms/step - loss: 0.5412 - mae: 0.4908 - val_loss: 0.6698 - val_mae: 0.5746 - learning_rate: 5.0000e-04\n",
      "\u001b[1m98/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 12ms/step\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.optimizers import AdamW\n",
    "\n",
    "timesteps = 12\n",
    "\n",
    "X_train_seq, y_train_seq = create_sequences(X_train_scaled, y_train_scaled, timesteps=timesteps)\n",
    "X_test_seq, y_test_seq = create_sequences(X_test_scaled, y_test_scaled, timesteps=timesteps)\n",
    "\n",
    "train_set = tf.data.Dataset.from_tensor_slices((X_train_seq, y_train_seq)).batch(16)\n",
    "test_set = tf.data.Dataset.from_tensor_slices((X_test_seq, y_test_seq)).batch(16)\n",
    "\n",
    "model_rnn = Sequential([\n",
    "    Input(shape=(timesteps, X_train_scaled.shape[1])),\n",
    "    \n",
    "    Bidirectional(LSTM(128, return_sequences=True, activation=\"tanh\")),  # Capture les tendances avant/arrière\n",
    "    Dropout(0.2),\n",
    "\n",
    "    Bidirectional(GRU(64, return_sequences=True, activation=\"tanh\")),  # GRU bidirectionnel\n",
    "    Dropout(0.2),\n",
    "    \n",
    "    GRU(32, return_sequences=False, activation=\"tanh\"),\n",
    "    Dropout(0.2),\n",
    "\n",
    "    Dense(16, activation=\"relu\"),\n",
    "    Dense(1)\n",
    "])\n",
    "\n",
    "model_rnn.compile(\n",
    "    loss=\"mse\",\n",
    "    optimizer=AdamW(learning_rate=0.001, weight_decay=1e-4),\n",
    "    metrics=[\"mae\"]\n",
    ")\n",
    "\n",
    "history = model_rnn.fit(X_train_seq, y_train_seq, epochs=10, batch_size=32, validation_data=(X_test_seq, y_test_seq), callbacks=[callbacks])\n",
    "y_pred_rnn = model_rnn.predict(X_test_seq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "id": "f9e1cf04-e589-40e3-92e4-d3ff592e4cad",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Modèle</th>\n",
       "      <th>Scaler</th>\n",
       "      <th>MAE</th>\n",
       "      <th>RMSE</th>\n",
       "      <th>R2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>RNN</td>\n",
       "      <td>robust</td>\n",
       "      <td>126459.016422</td>\n",
       "      <td>174482.246974</td>\n",
       "      <td>0.371986</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Modèle  Scaler            MAE           RMSE        R2\n",
       "0    RNN  robust  126459.016422  174482.246974  0.371986"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "scaler_y = robust_y_scaler\n",
    "display_scores(y_test_seq, y_pred_rnn, 'RNN', 'robust')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "id": "97f0bd2f-4718-4858-9122-3e092f7b9b92",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "\u001b[1m347/347\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 17ms/step - loss: 0.7217 - mae: 0.5991 - val_loss: 0.7307 - val_mae: 0.5645 - learning_rate: 0.0010\n",
      "Epoch 2/50\n",
      "\u001b[1m347/347\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 14ms/step - loss: 0.5987 - mae: 0.5309 - val_loss: 0.7215 - val_mae: 0.6203 - learning_rate: 0.0010\n",
      "Epoch 3/50\n",
      "\u001b[1m347/347\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 14ms/step - loss: 0.6025 - mae: 0.5262 - val_loss: 0.7351 - val_mae: 0.5718 - learning_rate: 0.0010\n",
      "Epoch 4/50\n",
      "\u001b[1m347/347\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 15ms/step - loss: 0.6085 - mae: 0.5276 - val_loss: 0.6619 - val_mae: 0.5823 - learning_rate: 0.0010\n",
      "Epoch 5/50\n",
      "\u001b[1m347/347\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 14ms/step - loss: 0.5717 - mae: 0.5072 - val_loss: 0.6830 - val_mae: 0.5605 - learning_rate: 0.0010\n",
      "Epoch 6/50\n",
      "\u001b[1m347/347\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 14ms/step - loss: 0.5686 - mae: 0.5058 - val_loss: 0.7119 - val_mae: 0.5687 - learning_rate: 0.0010\n",
      "Epoch 7/50\n",
      "\u001b[1m347/347\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 15ms/step - loss: 0.5544 - mae: 0.4981 - val_loss: 0.7606 - val_mae: 0.5913 - learning_rate: 0.0010\n",
      "Epoch 8/50\n",
      "\u001b[1m347/347\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 15ms/step - loss: 0.5666 - mae: 0.5038 - val_loss: 0.6994 - val_mae: 0.5632 - learning_rate: 0.0010\n",
      "Epoch 9/50\n",
      "\u001b[1m347/347\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 0.5468 - mae: 0.4969\n",
      "Epoch 9: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "\u001b[1m347/347\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 15ms/step - loss: 0.5468 - mae: 0.4969 - val_loss: 0.6939 - val_mae: 0.5903 - learning_rate: 0.0010\n",
      "Epoch 10/50\n",
      "\u001b[1m347/347\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 15ms/step - loss: 0.5223 - mae: 0.4858 - val_loss: 0.6851 - val_mae: 0.5618 - learning_rate: 5.0000e-04\n",
      "Epoch 11/50\n",
      "\u001b[1m347/347\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 14ms/step - loss: 0.5423 - mae: 0.4878 - val_loss: 0.6793 - val_mae: 0.5547 - learning_rate: 5.0000e-04\n",
      "Epoch 12/50\n",
      "\u001b[1m347/347\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 14ms/step - loss: 0.5194 - mae: 0.4770 - val_loss: 0.7066 - val_mae: 0.5762 - learning_rate: 5.0000e-04\n",
      "Epoch 13/50\n",
      "\u001b[1m347/347\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 15ms/step - loss: 0.5272 - mae: 0.4838 - val_loss: 0.6977 - val_mae: 0.5746 - learning_rate: 5.0000e-04\n",
      "Epoch 14/50\n",
      "\u001b[1m345/347\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 0.5213 - mae: 0.4765\n",
      "Epoch 14: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
      "\u001b[1m347/347\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 15ms/step - loss: 0.5213 - mae: 0.4765 - val_loss: 0.6789 - val_mae: 0.5623 - learning_rate: 5.0000e-04\n",
      "\u001b[1m98/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.layers import Add, GlobalAveragePooling1D\n",
    "\n",
    "input_layer = Input(shape=(timesteps, X_train_scaled.shape[1]))\n",
    "x = Bidirectional(LSTM(128, return_sequences=True, activation=\"tanh\"))(input_layer)\n",
    "x = GRU(64, return_sequences=True, activation=\"tanh\")(x)\n",
    "\n",
    "residual = x  \n",
    "x = LSTM(32, return_sequences=True, activation=\"tanh\")(x)\n",
    "\n",
    "residual = GlobalAveragePooling1D()(residual)\n",
    "x = GlobalAveragePooling1D()(x)\n",
    "\n",
    "residual = Dense(32, activation=\"tanh\")(residual)\n",
    "x = Add()([x, residual]) \n",
    "\n",
    "output_layer = Dense(1)(x)\n",
    "\n",
    "model_rnn = Model(inputs=input_layer, outputs=output_layer)\n",
    "\n",
    "model_rnn.compile(\n",
    "    loss=\"mse\",\n",
    "    optimizer=tf.keras.optimizers.AdamW(learning_rate=0.001, weight_decay=1e-4),\n",
    "    metrics=[\"mae\"]\n",
    ")\n",
    "\n",
    "history = model_rnn.fit(X_train_seq, y_train_seq, epochs=50, batch_size=32, validation_data=(X_test_seq, y_test_seq), callbacks=[callbacks])\n",
    "y_pred_rnn = model_rnn.predict(X_test_seq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "id": "995bf936-31a9-46e4-9c62-f30b2ba4f021",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Modèle</th>\n",
       "      <th>Scaler</th>\n",
       "      <th>MAE</th>\n",
       "      <th>RMSE</th>\n",
       "      <th>R2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>RNN</td>\n",
       "      <td>robust</td>\n",
       "      <td>125476.100855</td>\n",
       "      <td>175297.990699</td>\n",
       "      <td>0.3661</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Modèle  Scaler            MAE           RMSE      R2\n",
       "0    RNN  robust  125476.100855  175297.990699  0.3661"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "scaler_y = robust_y_scaler\n",
    "display_scores(y_test_seq, y_pred_rnn, 'RNN + residu', 'robust')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "id": "34a38dd6-a03e-4c48-910c-ab6628b43855",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install keras-tcn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "id": "1aa8fbea-337b-411d-a6a7-908ffc9a9950",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\tabod\\anaconda3\\Lib\\site-packages\\keras\\src\\backend\\tensorflow\\core.py:219: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional_25\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"functional_25\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                         </span>┃<span style=\"font-weight: bold\"> Output Shape                </span>┃<span style=\"font-weight: bold\">         Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
       "│ input_layer_29 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">12</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">30</span>)              │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ tcn (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">TCN</span>)                            │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)                  │          <span style=\"color: #00af00; text-decoration-color: #00af00\">94,272</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dropout_26 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)                  │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense_80 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)                  │           <span style=\"color: #00af00; text-decoration-color: #00af00\">2,080</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense_81 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)                   │              <span style=\"color: #00af00; text-decoration-color: #00af00\">33</span> │\n",
       "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                        \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape               \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m        Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
       "│ input_layer_29 (\u001b[38;5;33mInputLayer\u001b[0m)          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m12\u001b[0m, \u001b[38;5;34m30\u001b[0m)              │               \u001b[38;5;34m0\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ tcn (\u001b[38;5;33mTCN\u001b[0m)                            │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)                  │          \u001b[38;5;34m94,272\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dropout_26 (\u001b[38;5;33mDropout\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)                  │               \u001b[38;5;34m0\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense_80 (\u001b[38;5;33mDense\u001b[0m)                     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)                  │           \u001b[38;5;34m2,080\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense_81 (\u001b[38;5;33mDense\u001b[0m)                     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)                   │              \u001b[38;5;34m33\u001b[0m │\n",
       "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">96,385</span> (376.50 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m96,385\u001b[0m (376.50 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">96,385</span> (376.50 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m96,385\u001b[0m (376.50 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "\u001b[1m347/347\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 11ms/step - loss: 5.1346 - mae: 1.1647 - val_loss: 1.2270 - val_mae: 0.7445 - learning_rate: 0.0010\n",
      "Epoch 2/50\n",
      "\u001b[1m347/347\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 8ms/step - loss: 1.1246 - mae: 0.7113 - val_loss: 0.8600 - val_mae: 0.7225 - learning_rate: 0.0010\n",
      "Epoch 3/50\n",
      "\u001b[1m347/347\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 8ms/step - loss: 0.8795 - mae: 0.6423 - val_loss: 0.7836 - val_mae: 0.6858 - learning_rate: 0.0010\n",
      "Epoch 4/50\n",
      "\u001b[1m347/347\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 8ms/step - loss: 0.7602 - mae: 0.6162 - val_loss: 0.7763 - val_mae: 0.6786 - learning_rate: 0.0010\n",
      "Epoch 5/50\n",
      "\u001b[1m347/347\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 8ms/step - loss: 0.9242 - mae: 0.6183 - val_loss: 0.7042 - val_mae: 0.6180 - learning_rate: 0.0010\n",
      "Epoch 6/50\n",
      "\u001b[1m347/347\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 7ms/step - loss: 0.8489 - mae: 0.6049 - val_loss: 0.6894 - val_mae: 0.5777 - learning_rate: 0.0010\n",
      "Epoch 7/50\n",
      "\u001b[1m347/347\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 7ms/step - loss: 0.6777 - mae: 0.5670 - val_loss: 0.6886 - val_mae: 0.5924 - learning_rate: 0.0010\n",
      "Epoch 8/50\n",
      "\u001b[1m347/347\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 8ms/step - loss: 0.6234 - mae: 0.5450 - val_loss: 0.6770 - val_mae: 0.5746 - learning_rate: 0.0010\n",
      "Epoch 9/50\n",
      "\u001b[1m347/347\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 8ms/step - loss: 0.6515 - mae: 0.5510 - val_loss: 0.6912 - val_mae: 0.5676 - learning_rate: 0.0010\n",
      "Epoch 10/50\n",
      "\u001b[1m347/347\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 8ms/step - loss: 0.6432 - mae: 0.5329 - val_loss: 0.6748 - val_mae: 0.5746 - learning_rate: 0.0010\n",
      "Epoch 11/50\n",
      "\u001b[1m347/347\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 7ms/step - loss: 0.6134 - mae: 0.5324 - val_loss: 0.6713 - val_mae: 0.5660 - learning_rate: 0.0010\n",
      "Epoch 12/50\n",
      "\u001b[1m347/347\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 7ms/step - loss: 0.5799 - mae: 0.5181 - val_loss: 0.6829 - val_mae: 0.5763 - learning_rate: 0.0010\n",
      "Epoch 13/50\n",
      "\u001b[1m347/347\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 7ms/step - loss: 0.5642 - mae: 0.5084 - val_loss: 0.6671 - val_mae: 0.5568 - learning_rate: 0.0010\n",
      "Epoch 14/50\n",
      "\u001b[1m347/347\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 7ms/step - loss: 0.5738 - mae: 0.5166 - val_loss: 0.6692 - val_mae: 0.5723 - learning_rate: 0.0010\n",
      "Epoch 15/50\n",
      "\u001b[1m347/347\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 7ms/step - loss: 0.5523 - mae: 0.5039 - val_loss: 0.6832 - val_mae: 0.5898 - learning_rate: 0.0010\n",
      "Epoch 16/50\n",
      "\u001b[1m347/347\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 7ms/step - loss: 0.5440 - mae: 0.5021 - val_loss: 0.6846 - val_mae: 0.6046 - learning_rate: 0.0010\n",
      "Epoch 17/50\n",
      "\u001b[1m347/347\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 7ms/step - loss: 0.5541 - mae: 0.5005 - val_loss: 0.6951 - val_mae: 0.6159 - learning_rate: 0.0010\n",
      "Epoch 18/50\n",
      "\u001b[1m341/347\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.5433 - mae: 0.5003\n",
      "Epoch 18: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "\u001b[1m347/347\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 7ms/step - loss: 0.5433 - mae: 0.5003 - val_loss: 0.6950 - val_mae: 0.5784 - learning_rate: 0.0010\n",
      "Epoch 19/50\n",
      "\u001b[1m347/347\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 7ms/step - loss: 0.5098 - mae: 0.4823 - val_loss: 0.6912 - val_mae: 0.5727 - learning_rate: 5.0000e-04\n",
      "Epoch 20/50\n",
      "\u001b[1m347/347\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 8ms/step - loss: 0.4681 - mae: 0.4660 - val_loss: 0.7508 - val_mae: 0.5677 - learning_rate: 5.0000e-04\n",
      "Epoch 21/50\n",
      "\u001b[1m347/347\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 7ms/step - loss: 0.4781 - mae: 0.4634 - val_loss: 0.7415 - val_mae: 0.5782 - learning_rate: 5.0000e-04\n",
      "Epoch 22/50\n",
      "\u001b[1m347/347\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 8ms/step - loss: 0.4776 - mae: 0.4720 - val_loss: 0.7046 - val_mae: 0.5940 - learning_rate: 5.0000e-04\n",
      "Epoch 23/50\n",
      "\u001b[1m346/347\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.4368 - mae: 0.4444\n",
      "Epoch 23: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
      "\u001b[1m347/347\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 7ms/step - loss: 0.4369 - mae: 0.4444 - val_loss: 0.7337 - val_mae: 0.5890 - learning_rate: 5.0000e-04\n",
      "\u001b[1m98/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.optimizers import Adam\n",
    "from tcn import TCN\n",
    "\n",
    "timesteps = 12\n",
    "features = X_train_scaled.shape[1]\n",
    "\n",
    "input_layer = Input(shape=(timesteps, features))\n",
    "x = TCN(nb_filters=64, kernel_size=3, dilations=[1, 2, 4, 8], activation=\"relu\")(input_layer)\n",
    "x = Dropout(0.2)(x)\n",
    "x = Dense(32, activation=\"relu\")(x)\n",
    "output_layer = Dense(1)(x)\n",
    "\n",
    "model_tcn = Model(inputs=input_layer, outputs=output_layer)\n",
    "model_tcn.compile(\n",
    "    loss=\"mse\",\n",
    "    optimizer=Adam(learning_rate=0.001),\n",
    "    metrics=[\"mae\"]\n",
    ")\n",
    "\n",
    "model_tcn.summary()\n",
    "\n",
    "history = model_tcn.fit(\n",
    "    X_train_seq, y_train_seq, \n",
    "    epochs=50, batch_size=32, \n",
    "    validation_data=(X_test_seq, y_test_seq), \n",
    "    callbacks=[callbacks]\n",
    ")\n",
    "\n",
    "y_pred_tcn = model_tcn.predict(X_test_seq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "id": "db7c3c4c-ea88-42c2-85b6-f6fb63ee229f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Modèle</th>\n",
       "      <th>Scaler</th>\n",
       "      <th>MAE</th>\n",
       "      <th>RMSE</th>\n",
       "      <th>R2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>TCN</td>\n",
       "      <td>robust</td>\n",
       "      <td>119980.147568</td>\n",
       "      <td>175992.790121</td>\n",
       "      <td>0.361065</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Modèle  Scaler            MAE           RMSE        R2\n",
       "0    TCN  robust  119980.147568  175992.790121  0.361065"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "scaler_y = robust_y_scaler\n",
    "display_scores(y_test_seq, y_pred_tcn, 'TCN', 'robust')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
